import numpy as np
from pathlib import Path
from threading import Thread, Lock
from utilities.dfp_inspect import dfp_inspect
import mxa # mxa driver
import time

class Benchmark:
    """MemryX Benchmark.

    The interface to the MemryX Benchmark. This class wraps driver calls to
    provide a user friendly expereince using MXA(s) which are connected via
    PCIe/USB.

    Parameters
    ----------

        verbose : int
            How verbose the benchmark will be.

        dfp : string or bytearray
            Path to dfp or a dfp object (bytearray)

    Examples
    --------
    .. code-block:: python

        from memryx import Benchmark

        # Run inference with 100 frames of random data
        with Benchmark(dfp='mobilenet.dfp') as accl:
            outputs,latency,fps = accl.run(frames=100)
            print("Latency {.2f} ms | FPS {.2f}".format(latency*1000, fps))

    """

###############################################################################
    #@initializer
    def __init__(self, verbose=0, fps=0, dfp="model.dfp", group=0, model=0, chip_gen=3.1, **kwargs):
        if not mxa:
            raise Exception("driver package not installed! Please install the .deb/.rpm/.tgz and try again")

        if isinstance(dfp, (str, Path)) and not dfp.endswith('.dfp'):
            raise Exception(f"Input file: {dfp} is not a .dfp file generated by the NeuralCompiler")

        # Dataflow program
        self.dfp = dfp
        self.group = group
        self.model = model
        # Info
        self.towers = None
        self.gen = None
        self.mpus = None
        self.mpu_frequency = None
        # self.chip_gen = chip_gen

        self.num_inports = None
        self.num_outports = None
        self.input_ports= {}
        self.output_ports= {}

        self.fps = fps
        self.latency = None

        # dfp as bytes need to be saved to a tempfile, since the driver
        # currently requires download_model to use file args
        self.is_tempfile = False

        # Threading
        self.mxa_io_lock = Lock()
        self.outstanding_frames = 0
        self.frame_start_time, self.frame_stop_time = [],[]

        # Parse DFP
        self.__parse_dfp()

        if self.gen == "Cascade+":
            self.chip_gen = 3.1
        elif self.gen == "Cascade":
            self.chip_gen = 3

        # Hpoc
        hpoc_fname = kwargs.get('hpoc_fname', None)
        # self.__do_hpoc = bool(hpoc_fname)
        # hpoc channel already removed by driver
        self.__do_hpoc = 0
        self.__hpoc_mask = self.__gen_hpoc_mask(hpoc_fname)

###############################################################################
    def __gen_hpoc_mask(self, hpoc_fname):
        if hpoc_fname is None:
            return None

        with open(hpoc_fname, 'r') as f:
            hpoc = json.loads(f.read())
        return [np.array(v['channel_mask']).astype(bool) for k,v in hpoc.items()]

###############################################################################
    def __enter__(self):
        # Initialize and lock the driver
        try:
            self.__init_driver()
        except Exception as e:
            self.__close()
            mxa.unlock(self.group)
            raise e

        return self

###############################################################################
    def __exit__(self, type, value, traceback):
        self.__close()
        mxa.unlock(self.group)

        if self.is_tempfile:
            os.remove(self.dfp)

        if type:
            return False
        else:
            return True

###############################################################################
    @staticmethod
    def parse():
        """
        """

        parser = argparse.ArgumentParser(
                 description = "\033[34mMemryX Benchmark\033[0m")

        parser.add_argument(   "-v","--verbose",
                                dest    =   "verbose",
                                action  =   "count",
                                default =   0,
                                help    =   "set the level of verbose messaging")

        parser.add_argument(   "-d","--dfp",
                                dest    =   "dfp",
                                action  =   "store",
                                default =   "model.dfp",
                                help="path to .dfp file (default: ./model.dfp)",
                                metavar="")

        parser.add_argument(   "-f","--frames",
                                dest    =   "frames",
                                type    =   int,
                                action  =   "store",
                                default =   100,
                                help="Set the number of frames to run (default: 100)",
                                metavar="")

        parser.add_argument(   "-g","--group",
                                dest    =   "group",
                                type    =   int,
                                action  =   "store",
                                default =   0,
                                help="Set the group number (default: 0)",
                                metavar="")

        parser.add_argument(   "-m","--model",
                                dest    =   "model",
                                type    =   int,
                                action  =   "store",
                                default =   0,
                                help="Set the model number (default: 0)",
                                metavar="")

        parser.add_argument(   "--hello",
                                dest    =   "hello",
                                action  =   "store_true",
                                default =   False,
                                help="Say hello from the MXA.")

        parser.add_argument(   "--chip_gen",
                                dest    =   "chip_gen",
                                type    =   float,
                                action  =   "store",
                                default =   3.1,
                                help="Set the chip gen(default: 3.1)")

        return vars(parser.parse_args())

###############################################################################
    def __parse_dfp(self):
        """
        Parse metadata from the DFP
        """

        if not self.dfp:
            raise Exception(f"no DFP file or object given to Benchmark")

        if type(self.dfp) is bytearray:
            tmpfile = tempfile.NamedTemporaryFile(mode='wb',delete=False, suffix='.dfp')
            tmpfile.write(self.dfp)
            self.dfp = tmpfile.name
            tmpfile.close()
            self.is_tempfile = True

        self._sys_info = _SystemInfo(self.dfp)
        for attr_name in ['towers', 'mpus', 'gen', 'mpu_frequency',
                'num_inports', 'num_outports', 'input_ports', 'output_ports']:
            setattr(self, attr_name, getattr(self._sys_info, attr_name))

##  Driver  ###################################################################
    def __init_driver(self):
        # Open mxa
        mxa.lock(self.group)
        err = mxa.open(self.model, self.group, self.chip_gen)
        if err:
            raise Exception("Failed to open MXA")

        # increase queue sizes
        err = mxa.set_ifmap_queue_size(self.model, 10)
        if err:
            raise Exception("Failed to set ifmap queue size")
        err = mxa.set_ofmap_queue_size(self.model, 10)
        if err:
            raise Exception("Failed to set ofmap queue size")

        hw_mpus = mxa.chip_count(self.group)
        dfp_mpus = self._sys_info.mpus

        if self.gen == "Cascade":
            if hw_mpus != dfp_mpus:
                raise Exception(f"Input DFP was compiled for {dfp_mpus} chips, but the connected accelerator has {hw_mpus} chips")
        elif self.gen == "Cascade+":
            if dfp_mpus == 1:
                mxa.config_mpu_group(self.group, 2)
            elif dfp_mpus == 2:
                mxa.config_mpu_group(self.group, 4)
            elif dfp_mpus == 3:
                mxa.config_mpu_group(self.group, 3)
            elif dfp_mpus == 4:
                mxa.config_mpu_group(self.group, 0)
            elif dfp_mpus == 8:
                mxa.config_mpu_group(self.group, 5)
            elif dfp_mpus == 12:
                mxa.config_mpu_group(self.group, 6)
            elif dfp_mpus == 16:
                mxa.config_mpu_group(self.group, 7)
            else:
                raise Exception(f"Input DFP was compiled for {dfp_mpus} chips, but the connected accelerator has {hw_mpus} chips")
        else:
            raise Exception(f"Unsupport generation {self.gen} chips")


        # Download the dfp
        err = mxa.download(self.model, self.dfp, 0, 3)
        if err:
            raise Exception("Failed to download DFP to mxa!")

        # start the driver workers
        mxa.set_stream_enable(self.model, 0)

###############################################################################
    def __close(self):
        mxa.close(self.model)
        time.sleep(0.01)

###############################################################################
    def run(self, inputs=None, frames=100, threading=True):
        """ Run inference on the benchmark.

        Perform inference using the configured DFP on the connected MXA with the given inputs or random data if no
        inputs are specified.

        Parameters
        ----------
        inputs : np.array() or list of np.array()
            The array shape should be [N + input_shape] where N is the number
            of frames to run. If there are multiple inputs to the
            DFP (e.g. multi-model) then a list of (appropriately shaped) numpy
            arrays.

        frames : int
            Number of frames to run. The number of frames in 'inputs' args will
            override this. (defaults to 100).

        threading : bool
            Use threading to send / recieve frame. This will allow frames to be
            pipelined on the accelerator which enables higher FPS. Otherwise a
            blocking scheme to send / receive frames will be used.

            .. note::

                You must use `threading=False` in order to measure latency. On the other
                hand, use `threading=True` to get the best FPS.

        Returns
        -------
        outputs, latency, fps : np.array() or list of np.array(), float, float
            Produces the NN output (only when `inputs` is provided) and reports the
            latency and/or FPS. The output data is returned as a list of np.array().
            The arrays will have the shape [N + output_shape] for each output where
            N is the number of inference frames. When `inputs` is None, `outputs` will
            also be None since random inputs lead to random output feature maps.

            .. note::

                The latency is timed from the moment the first data of the
                input is consumed until the last data of the output produced.
                The FPS is calculated as the time between output frames.

            .. note::

                You must use `threading=False` in order to measure latency. On the other
                hand, use `threading=True` to get the best FPS.

        Raises
        ------
        ValueError :
            When the input is incorrectly configured.

        Examples
        --------
        .. code-block:: python

            with Benchmark(dfp='mobilenet.dfp') as accl:
                # 100 frames, get FPS
                outputs,_,fps = accl.run(frames=100)

                # single frame, get latency
                outputs,latency,_ = accl.run(threading=False)

                # four frames of a numpy array's data (assume 224x224x3 model input)
                inputs = np.zeros([4,224,224,3])
                outputs,latency,fps = accl.run(inputs=inputs)

        """

        ifmaps = inputs
        if ifmaps is None:
            # Generate random ifmaps with 1 frame per port, that will be re-used `frames` times to save memory
            self._random_inputs = True
            ifmaps = []
            for i,info in self.input_ports.items():
                if not info['active']:
                    continue
                row,col,z,ch = info['shape'][0],info['shape'][1],info['shape'][2],info['shape'][3]
                if (info['data_range_enabled'] == 1) or (info['data_type'].lower() in ["float"]):
                    ifmaps.append( np.random.random([1, row, col, z, ch]).astype(np.float32) )
                elif info['data_type'].lower() in  ["uint8", "rgb565", "yuv422", "yuy2"]:
                    ifmaps.append( (np.random.random([1, row, col, z, ch])*256).astype(np.uint8) )
                else:
                    raise Exception("ifmap format '{}' not supported in DFP!".format(info['packing_format']))

            # Create ofmaps with single frame that will be overwritten `frames` times
            ofmaps = []
            for i,info in self.output_ports.items():
                if not info['active']:
                    continue
                row,col,z,ch = info['shape'][0],info['shape'][1],info['shape'][2],info['shape'][3]
                ofmaps.append(np.zeros([1, row, col, z, ch], dtype=np.float32))
                        # Create full ofmaps

        else:
            self._random_inputs = False
            # Validate ifmaps are correctly shaped
            if type(ifmaps) is not type([]):
                ifmaps = [ifmaps]

            for i, p in enumerate(ifmaps):
                if type(p) is not type(np.array([])):
                    raise TypeError("inputs is not an numpy.array() or list of numpy.array()")
                if self.input_ports[i]['active'] is False:
                    raise ValueError("port {} specified but not configured in DFP".format(i))
                size = np.prod(self.input_ports[i]['shape'])
                if size != p[0,...].size:
                    raise ValueError("expected size {} but got {} for port {}"
                        .format(size, p[0,...].size, i))
            frames = ifmaps[0].shape[0]

            # Create full ofmaps
            ofmaps = []
            for i,info in self.output_ports.items():
                if not info['active']:
                    continue
                row,col,z,ch = info['shape'][0],info['shape'][1],info['shape'][2],info['shape'][3]
                ofmaps.append(np.zeros([frames, row, col, z, ch], dtype=np.float32))


        # Run inference
        if threading:
            if (self.fps > 0):
                threads = [Thread(target=self.__send_fps, args=(ifmaps,frames,), daemon=True),
                    Thread(target=self.__receive, args=(ofmaps,frames,), daemon=True)]
            else:
                threads = [Thread(target=self.__send, args=(ifmaps,frames,), daemon=True),
                    Thread(target=self.__receive, args=(ofmaps,frames,), daemon=True)]
            start = time.time()
            [t.start() for t in threads]
            [t.join() for t in threads]
            dt = time.time() - start

            latency = -1
            fps = frames / dt
        else:
            # Completely blocking
            start = time.time()
            for f in range(frames):
                # Sending
                for p,ifmap in enumerate(ifmaps):
                    if (self.input_ports[p]['data_range_enabled'] == 0) and \
                       (self.input_ports[p]['data_type'].lower() in ["uint8", "rgb565", "yuv422", "yuy2"]):
                        err = mxa.stream_ifmap(self.model, p, ifmap[self.__get_frame_idx(f)].astype(np.uint8))
                    else:
                        err = mxa.stream_ifmap(self.model, p, ifmap[self.__get_frame_idx(f)].astype(np.float32))

                    if err:
                        raise Exception(f"stream_ifmap failed with code {err}")

                # Receiving
                for p,ofmap in enumerate(ofmaps):
                    err = mxa.stream_ofmap(self.model, p, ofmap[self.__get_frame_idx(f),...])
                    if err:
                        raise Exception(f"stream_ofmap failed with code {err}")

            dt = time.time() - start
            latency = dt / frames * 1000
            fps = frames / dt

        # hpoc
        if self.__do_hpoc:
            ofmaps_hpoc = []
            for ofmap,mask in zip(ofmaps,self.__hpoc_mask):
                ofmaps_hpoc.append(ofmap[:,:,:,mask])
            ofmaps = ofmaps_hpoc

        if self._random_inputs:
            return None, latency, fps
        return ofmaps.copy(), latency, fps

    # threaded sender
    def __send(self, ifmaps, frames):
        frame_num = 0
        while frame_num < frames:
            for p,ifmap in enumerate(ifmaps):
                if (self.input_ports[p]['data_range_enabled'] == 0) and (self.input_ports[p]['data_type'].lower() in ['uint8', 'rgb565', 'yuv422', 'yuy2']):
                    err = mxa.stream_ifmap(self.model, p, ifmap[self.__get_frame_idx(frame_num)].astype(np.uint8))
                else:
                    err = mxa.stream_ifmap(self.model, p, ifmap[self.__get_frame_idx(frame_num)].astype(np.float32))
                if err:
                    raise Exception('stream_ifmap err', err)

            frame_num += 1

    # threaded sender
    def __send_fps(self, ifmaps, frames):
        frame_num = 0
        time_end = 0
        time_start = time.time()
        latency = 1000 / self.fps #ms

        while frame_num < frames:
            for p,ifmap in enumerate(ifmaps):
                if (self.input_ports[p]['data_range_enabled'] == 0) and (self.input_ports[p]['data_type'].lower() in ['uint8', 'rgb565', 'yuv422', 'yuy2']):
                    err = mxa.stream_ifmap(self.model, p, ifmap[self.__get_frame_idx(frame_num)].astype(np.uint8))
                else:
                    err = mxa.stream_ifmap(self.model, p, ifmap[self.__get_frame_idx(frame_num)].astype(np.float32))
                if err:
                    raise Exception('stream_ifmap err', err)

            frame_num += 1

            if (frame_num < frames):
                while ((time.time() - time_start) * 1000) < latency:
                    pass
                time_start = time.time()
    # threaded receiver
    def __receive(self, ofmaps, frames):
        frame_num = 0
        while frame_num < frames:

            for p,ofmap in enumerate(ofmaps):
                err = mxa.stream_ofmap(self.model, p, ofmap[self.__get_frame_idx(frame_num),...])
                if err:
                    raise Exception('stream_ofmap err', err)
            frame_num += 1

    def __get_frame_idx(self, idx):
        return 0 if self._random_inputs else idx

def calculate_latency(time_points):
    time_points = np.array(sorted(time_points))

    std = np.std(time_points[:-1])
    mean = np.average(time_points[:-1])

    filtered_time_points = time_points[time_points < mean+3*std]
    filtered_time_points = filtered_time_points[filtered_time_points > mean-3*std]

    return np.average(filtered_time_points)

def main():

    # Instantiate mxa
    args = Benchmark.parse()

    # Create inputs
    with Benchmark(**args) as a:
        start = time.time()
        outputs,fakelatency,fps = a.run(frames=args['frames'])
        dt = time.time() - start
        print("Ran {} frames in {:.1f} ms".format(args['frames'], dt * 1000.0))
        print("  Average FPS: {}{:.2f}{} ".format(fps))

    '''
    with Benchmark(**args) as a:
        latency_time_points = []
        for i in range(20):
            _,latency,_ = a.run(frames=1,threading=False)
            latency_time_points.append(latency)
        latency = calculate_latency(latency_time_points)
        print("  Average Latency: {}{:.2f}{} ms".format(latency))
    '''

class _SystemInfo:
    def __init__(self, dfp_path):
        dfp_file = open(dfp_path, 'rb')

        meta = dfp_inspect(dfp_path)
        self.dfp_version = meta['dfp_version']
        self.towers = meta['sim_info']['towers']
        self.mpus = meta['num_mxas']
        self.gen = meta['mxa_gen']
        self.mpu_frequency = meta['sim_info']['frequency']
        self.num_inports = meta['num_inports']
        self.num_outports = meta['num_outports']

        self.input_ports = meta['input_ports']
        self.output_ports = meta['output_ports']

